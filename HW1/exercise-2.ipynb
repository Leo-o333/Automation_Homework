{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "987d4c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas  as pd #Data manipulation\n",
    "import numpy as np #Data manipulation\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "import seaborn as sns #Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "792c0ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.714274</td>\n",
       "      <td>0.989079</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.661432</td>\n",
       "      <td>6.846034</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.360534</td>\n",
       "      <td>3.359866</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.720238</td>\n",
       "      <td>2.021597</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.959555</td>\n",
       "      <td>8.563527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2  y\n",
       "0  4.714274  0.989079  2\n",
       "1  1.661432  6.846034  2\n",
       "2  1.360534  3.359866  2\n",
       "3  1.720238  2.021597  2\n",
       "4  4.959555  8.563527  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_data = pd.read_csv('classification.csv', sep = ',')\n",
    "classification_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7d1ea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "81839bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import random\n",
    "validate = np.ndarray(shape = (10, 30))\n",
    "# validate_std  = np.ndarray(shape = (10, 30))\n",
    "accurary = np.ndarray(shape = (10, 30))\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    random.seed(i)\n",
    "    # shuffle data for 10 time\n",
    "#!!!!Don't delete frac = 1\n",
    "### For information about frac = 1, see this website: https://stackoverflow.com/questions/29576430/shuffle-dataframe-rows\n",
    "    shuffeled_data =classification_data.sample(frac=1).reset_index(drop = True)\n",
    "    splited_data = [shuffeled_data.loc[:20]]\n",
    "    splited_data.append(shuffeled_data.loc[20:])\n",
    "    #check the splited daata\n",
    "    \n",
    "    ## first get the original 20 points of the \n",
    "    train_X = splited_data[0][[\"x1\",\"x2\"]].values\n",
    "    train_Y = splited_data[0][\"y\"].values\n",
    "    test_X = splited_data[1][[\"x1\",\"x2\"]].values\n",
    "    test_Y = splited_data[1][\"y\"].values\n",
    "\n",
    "#     print(test_X,type(test_Y))\n",
    "    clf = svm.SVC(kernel='linear').fit(train_X,train_Y)\n",
    "\n",
    "    scores = cross_val_score(clf,train_X,train_Y,scoring='accuracy', cv = 5)\n",
    "\n",
    "#     print(scores, \"scores\")\n",
    "    ###################### Question: should I just do the average at here???????////\n",
    "    validate[i,0] = np.mean(scores)\n",
    "\n",
    "    y_pred = clf.predict(test_X)\n",
    "\n",
    "    accurary[i,0] = accuracy_score(test_Y, y_pred)\n",
    "\n",
    "#     print(\"validate\",validate,\"accuracu\",accurary, i, j)\n",
    "#     print('shape of textX ',test_X[0])\n",
    "    for j in range(1,30):\n",
    "        train_X = np.concatenate((train_X, [test_X[0]]))\n",
    "\n",
    "        train_Y = np.concatenate((train_Y,[test_Y[0]]))\n",
    "#         print(train_Y )\n",
    "#         print(train_X,train_Y)\n",
    "        test_X = np.delete(test_X, 0,0)\n",
    "        test_Y = np.delete(test_Y, 0,0)\n",
    "#         print(test_Y, len(test_X))\n",
    "        clf = svm.SVC(kernel='linear').fit(train_X,train_Y)\n",
    "\n",
    "        scores = cross_val_score(clf,train_X,train_Y,scoring='accuracy', cv = 5)\n",
    "\n",
    "        validate[i,j] = np.mean(scores)\n",
    "        \n",
    "        y_pred = clf.predict(test_X)\n",
    "        accurary[i,j] = accuracy_score(test_Y, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b11c5f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57       0.58       0.57       0.59       0.6        0.73333333\n",
      "  0.78666667 0.72666667 0.76       0.7        0.70952381 0.6952381\n",
      "  0.7047619  0.7047619  0.71428571 0.725      0.71071429 0.71428571\n",
      "  0.74642857 0.75       0.73888889 0.77222222 0.77222222 0.75\n",
      "  0.71111111 0.74       0.70666667 0.70888889 0.70888889 0.7       ]\n",
      " [0.86       0.78       0.78       0.8        0.72       0.76666667\n",
      "  0.9        0.82666667 0.82666667 0.83333333 0.84285714 0.85238095\n",
      "  0.79047619 0.73333333 0.68571429 0.69285714 0.7        0.67857143\n",
      "  0.65714286 0.725      0.75555556 0.68888889 0.74166667 0.72222222\n",
      "  0.68888889 0.71555556 0.72       0.70444444 0.67333333 0.7       ]\n",
      " [0.82       0.86       0.87       0.88       0.84       0.84666667\n",
      "  0.85333333 0.86       0.79333333 0.8        0.8047619  0.81428571\n",
      "  0.85238095 0.85714286 0.85714286 0.86071429 0.89285714 0.84285714\n",
      "  0.87142857 0.875      0.87777778 0.88055556 0.86111111 0.86388889\n",
      "  0.86666667 0.86888889 0.87333333 0.87555556 0.87777778 0.86      ]\n",
      " [0.71       0.79       0.8        0.8        0.76       0.77333333\n",
      "  0.78666667 0.79333333 0.76       0.76666667 0.80952381 0.81904762\n",
      "  0.81904762 0.82380952 0.85714286 0.83571429 0.84285714 0.81785714\n",
      "  0.82142857 0.825      0.83055556 0.83611111 0.81388889 0.79166667\n",
      "  0.8        0.80666667 0.76222222 0.80888889 0.78888889 0.8       ]\n",
      " [0.85       0.88       0.88       0.88       0.96       0.81333333\n",
      "  0.85333333 0.77333333 0.85333333 0.86666667 0.84285714 0.74761905\n",
      "  0.81428571 0.84761905 0.85714286 0.86071429 0.83571429 0.86428571\n",
      "  0.79642857 0.8        0.78055556 0.80833333 0.81388889 0.84166667\n",
      "  0.82222222 0.84888889 0.82666667 0.81111111 0.81333333 0.82      ]\n",
      " [0.72       0.79       0.79       0.8        0.76       0.88666667\n",
      "  0.84666667 0.82       0.82       0.83333333 0.83809524 0.80952381\n",
      "  0.81904762 0.85714286 0.77142857 0.80714286 0.81428571 0.81785714\n",
      "  0.82142857 0.825      0.80555556 0.78611111 0.81666667 0.77222222\n",
      "  0.8        0.80666667 0.80888889 0.79111111 0.79333333 0.8       ]\n",
      " [0.95       0.95       0.96       0.91       0.84       0.88\n",
      "  0.88666667 0.92666667 0.93333333 0.86666667 0.83333333 0.84285714\n",
      "  0.81904762 0.82380952 0.82857143 0.75       0.72857143 0.76428571\n",
      "  0.82142857 0.825      0.82777778 0.83611111 0.77222222 0.8\n",
      "  0.8        0.89111111 0.84888889 0.87777778 0.86       0.86      ]\n",
      " [0.52       0.5        0.51       0.53       0.6        0.58\n",
      "  0.63333333 0.68       0.6        0.7        0.71428571 0.74761905\n",
      "  0.72857143 0.76666667 0.71428571 0.66785714 0.725      0.71428571\n",
      "  0.74285714 0.725      0.73611111 0.71666667 0.74722222 0.725\n",
      "  0.75555556 0.76444444 0.77111111 0.70888889 0.71111111 0.72      ]\n",
      " [0.81       0.78       0.79       0.88       0.84       0.80666667\n",
      "  0.78       0.79333333 0.82666667 0.83333333 0.83809524 0.84761905\n",
      "  0.85238095 0.82380952 0.8        0.775      0.81071429 0.75714286\n",
      "  0.76071429 0.775      0.775      0.76111111 0.76388889 0.76666667\n",
      "  0.8        0.74       0.74666667 0.72888889 0.75333333 0.76      ]\n",
      " [0.63       0.69       0.57       0.66       0.68       0.58666667\n",
      "  0.56       0.62       0.62666667 0.63333333 0.65238095 0.62857143\n",
      "  0.60952381 0.61904762 0.6        0.67142857 0.68214286 0.63214286\n",
      "  0.64285714 0.7        0.65833333 0.66944444 0.60555556 0.61388889\n",
      "  0.62222222 0.67555556 0.68222222 0.66666667 0.69777778 0.7       ]] acc [[0.775      0.7721519  0.76923077 0.76623377 0.76315789 0.78666667\n",
      "  0.78378378 0.73972603 0.73611111 0.73239437 0.72857143 0.72463768\n",
      "  0.72058824 0.73134328 0.72727273 0.72307692 0.71875    0.71428571\n",
      "  0.70967742 0.62295082 0.61666667 0.61016949 0.60344828 0.66666667\n",
      "  0.69642857 0.70909091 0.72222222 0.71698113 0.75       0.74509804]\n",
      " [0.8125     0.81012658 0.80769231 0.79220779 0.78947368 0.78666667\n",
      "  0.7972973  0.75342466 0.75       0.74647887 0.74285714 0.73913043\n",
      "  0.76470588 0.73134328 0.71212121 0.72307692 0.703125   0.73015873\n",
      "  0.80645161 0.72131148 0.71666667 0.71186441 0.72413793 0.71929825\n",
      "  0.71428571 0.70909091 0.74074074 0.73584906 0.73076923 0.7254902 ]\n",
      " [0.85       0.84810127 0.84615385 0.81818182 0.81578947 0.82666667\n",
      "  0.82432432 0.82191781 0.80555556 0.8028169  0.84285714 0.84057971\n",
      "  0.83823529 0.82089552 0.83333333 0.83076923 0.78125    0.80952381\n",
      "  0.80645161 0.80327869 0.8        0.79661017 0.82758621 0.8245614\n",
      "  0.82142857 0.81818182 0.77777778 0.77358491 0.76923077 0.74509804]\n",
      " [0.7375     0.73417722 0.74358974 0.74025974 0.71052632 0.70666667\n",
      "  0.7027027  0.69863014 0.69444444 0.69014085 0.75714286 0.75362319\n",
      "  0.75       0.73134328 0.72727273 0.73846154 0.734375   0.73015873\n",
      "  0.70967742 0.73770492 0.73333333 0.72881356 0.75862069 0.8245614\n",
      "  0.82142857 0.81818182 0.83333333 0.83018868 0.82692308 0.84313725]\n",
      " [0.7375     0.73417722 0.73076923 0.72727273 0.80263158 0.74666667\n",
      "  0.77027027 0.76712329 0.76388889 0.76056338 0.77142857 0.76811594\n",
      "  0.76470588 0.79104478 0.78787879 0.78461538 0.78125    0.76190476\n",
      "  0.75806452 0.75409836 0.75       0.74576271 0.74137931 0.73684211\n",
      "  0.76785714 0.76363636 0.77777778 0.79245283 0.78846154 0.78431373]\n",
      " [0.775      0.7721519  0.76923077 0.76623377 0.76315789 0.77333333\n",
      "  0.7972973  0.79452055 0.79166667 0.78873239 0.78571429 0.7826087\n",
      "  0.73529412 0.73134328 0.72727273 0.72307692 0.71875    0.71428571\n",
      "  0.72580645 0.72131148 0.73333333 0.72881356 0.72413793 0.71929825\n",
      "  0.73214286 0.72727273 0.72222222 0.69811321 0.69230769 0.68627451]\n",
      " [0.7875     0.78481013 0.78205128 0.76623377 0.81578947 0.81333333\n",
      "  0.81081081 0.80821918 0.80555556 0.8028169  0.78571429 0.7826087\n",
      "  0.80882353 0.80597015 0.8030303  0.81538462 0.8125     0.80952381\n",
      "  0.80645161 0.80327869 0.8        0.79661017 0.79310345 0.80701754\n",
      "  0.80357143 0.8        0.7962963  0.79245283 0.78846154 0.74509804]\n",
      " [0.7625     0.79746835 0.83333333 0.83116883 0.81578947 0.81333333\n",
      "  0.81081081 0.80821918 0.80555556 0.8028169  0.81428571 0.84057971\n",
      "  0.85294118 0.85074627 0.86363636 0.84615385 0.84375    0.85714286\n",
      "  0.83870968 0.83606557 0.83333333 0.83050847 0.84482759 0.84210526\n",
      "  0.85714286 0.85454545 0.83333333 0.81132075 0.86538462 0.82352941]\n",
      " [0.7125     0.70886076 0.70512821 0.7012987  0.69736842 0.66666667\n",
      "  0.66216216 0.65753425 0.65277778 0.64788732 0.64285714 0.63768116\n",
      "  0.63235294 0.67164179 0.65151515 0.64615385 0.75       0.6984127\n",
      "  0.69354839 0.68852459 0.76666667 0.77966102 0.77586207 0.77192982\n",
      "  0.75       0.70909091 0.72222222 0.71698113 0.71153846 0.70588235]\n",
      " [0.7375     0.73417722 0.73076923 0.72727273 0.72368421 0.72\n",
      "  0.72972973 0.7260274  0.72222222 0.71830986 0.74285714 0.73913043\n",
      "  0.75       0.74626866 0.75757576 0.75384615 0.75       0.76190476\n",
      "  0.75806452 0.81967213 0.81666667 0.74576271 0.74137931 0.73684211\n",
      "  0.76785714 0.76363636 0.75925926 0.69811321 0.69230769 0.68627451]]\n"
     ]
    }
   ],
   "source": [
    "print(validate, 'acc',accurary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "249f8459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.31272374 2.6233942 ] decision_sample\n",
      "[0.37026921 7.95533397] decision_sample\n",
      "[3.92531938 4.06247948] decision_sample\n",
      "[9.96619419 9.53116991] decision_sample\n",
      "[3.80381738 6.02428607] decision_sample\n",
      "[6.16207264 3.01948651] decision_sample\n",
      "[6.01026158 9.16495206] decision_sample\n",
      "[3.80381738 6.02428607] decision_sample\n",
      "[2.42063567 6.26646876] decision_sample\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tiant\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\tiant\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\tiant\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17597972 8.40114465] decision_sample\n"
     ]
    }
   ],
   "source": [
    "#### part II, using uncertainty sampling\n",
    "validate = np.ndarray(shape = (10, 30))\n",
    "# validate_std  = np.ndarray(shape = (10, 30))\n",
    "accurary = np.ndarray(shape = (10, 30))\n",
    "for i in range(10):\n",
    "    random.seed(i)\n",
    "    shuffeled_data =classification_data.sample(frac=1).reset_index(drop = True)\n",
    "    ### split data set\n",
    "    splited_data = [shuffeled_data.loc[:20]]\n",
    "    splited_data.append(shuffeled_data.loc[20:])\n",
    "    ### Transform dataframe into np array\n",
    "    train_X = splited_data[0][[\"x1\",\"x2\"]].values\n",
    "    train_Y = splited_data[0][\"y\"].values\n",
    "    test_X = splited_data[1][[\"x1\",\"x2\"]].values\n",
    "    test_Y = splited_data[1][\"y\"].values\n",
    "    ### calculate\n",
    "    clf = svm.SVC(kernel='linear',probability=True).fit(train_X,train_Y)\n",
    "    scores = cross_val_score(clf,train_X,train_Y,scoring='accuracy', cv = 5)\n",
    "#     print(scores, \"scores\")\n",
    "    ###################### Question: should I just do the average at here???????////\n",
    "    validate[i,0] = np.mean(scores)\n",
    "    y_pred = clf.predict(test_X)\n",
    "    decision_sample =test_X[np.argmin(np.abs(clf.decision_function(test_X)))] \n",
    "    print(decision_sample, \"decision_sample\")\n",
    "#     print(y_pred)\n",
    "    accurary[i,0] = accuracy_score(test_Y, y_pred)\n",
    "#     print(\"validate\",validate,\"accuracu\",accurary, i, j)\n",
    "#     print('shape of textX ',test_X[0])\n",
    "    for j in range(1,30):\n",
    "        train_X = np.concatenate((train_X, [test_X[0]]))\n",
    "\n",
    "        train_Y = np.concatenate((train_Y,[test_Y[0]]))\n",
    "#         print(train_Y )\n",
    "#         print(train_X,train_Y)\n",
    "        test_X = np.delete(test_X, 0,0)\n",
    "        test_Y = np.delete(test_Y, 0,0)\n",
    "#         print(test_Y, len(test_X))\n",
    "        clf = svm.SVC(kernel='linear').fit(train_X,train_Y)\n",
    "\n",
    "        scores = cross_val_score(clf,train_X,train_Y,scoring='accuracy', cv = 5)\n",
    "\n",
    "        validate[i,j] = np.mean(scores)\n",
    "        \n",
    "        y_pred = clf.predict(test_X)\n",
    "        accurary[i,j] = accuracy_score(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f093de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.96       0.96       0.87       0.87       0.88       0.77333333\n",
      "  0.74       0.74666667 0.76       0.76666667 0.77619048 0.78571429\n",
      "  0.75238095 0.7952381  0.8        0.80714286 0.78571429 0.76428571\n",
      "  0.79642857 0.825      0.82777778 0.80555556 0.78888889 0.79166667\n",
      "  0.86666667 0.82444444 0.80444444 0.78888889 0.75555556 0.76      ]\n",
      " [0.67       0.68       0.65       0.67       0.68       0.69333333\n",
      "  0.74       0.75333333 0.76       0.76666667 0.77619048 0.68571429\n",
      "  0.76190476 0.85714286 0.74285714 0.86071429 0.81071429 0.73571429\n",
      "  0.71785714 0.725      0.73055556 0.73611111 0.73888889 0.75277778\n",
      "  0.73333333 0.74       0.72444444 0.74888889 0.75777778 0.76      ]\n",
      " [0.62       0.59       0.7        0.63       0.56       0.57333333\n",
      "  0.67333333 0.68666667 0.66       0.63333333 0.64285714 0.66190476\n",
      "  0.67142857 0.64761905 0.62857143 0.66785714 0.70714286 0.63571429\n",
      "  0.71785714 0.675      0.63333333 0.69166667 0.725      0.73333333\n",
      "  0.75555556 0.76       0.74666667 0.75333333 0.75777778 0.76      ]\n",
      " [0.76       0.77       0.78       0.75       0.72       0.69333333\n",
      "  0.74       0.68       0.72666667 0.73333333 0.74285714 0.66190476\n",
      "  0.67619048 0.59047619 0.65714286 0.69642857 0.70714286 0.60714286\n",
      "  0.58928571 0.55       0.53888889 0.57222222 0.58611111 0.59444444\n",
      "  0.64444444 0.63333333 0.59777778 0.60666667 0.59333333 0.64      ]\n",
      " [0.8        0.85       0.85       0.83       0.8        0.76\n",
      "  0.76666667 0.78       0.79333333 0.83333333 0.83333333 0.8047619\n",
      "  0.81904762 0.76190476 0.8        0.82857143 0.80714286 0.81785714\n",
      "  0.82142857 0.8        0.8        0.85277778 0.88333333 0.84444444\n",
      "  0.82222222 0.82222222 0.82666667 0.79111111 0.77333333 0.78      ]\n",
      " [0.8        0.81       0.83       0.84       0.76       0.76\n",
      "  0.77333333 0.82       0.9        0.83333333 0.83809524 0.80952381\n",
      "  0.85238095 0.82380952 0.82857143 0.80357143 0.81071429 0.84285714\n",
      "  0.84642857 0.85       0.85555556 0.86111111 0.84166667 0.84166667\n",
      "  0.82222222 0.82666667 0.87333333 0.87777778 0.88       0.88      ]\n",
      " [0.66       0.72       0.74       0.71       0.76       0.76666667\n",
      "  0.81333333 0.78666667 0.78666667 0.7        0.80952381 0.74761905\n",
      "  0.76190476 0.72857143 0.71428571 0.77857143 0.78571429 0.76785714\n",
      "  0.8        0.775      0.80555556 0.83333333 0.86388889 0.86666667\n",
      "  0.86666667 0.84888889 0.85111111 0.79333333 0.73555556 0.76      ]\n",
      " [0.86       0.87       0.83       0.67       0.72       0.73333333\n",
      "  0.77333333 0.79333333 0.75333333 0.76666667 0.77142857 0.65238095\n",
      "  0.62857143 0.64285714 0.65714286 0.69642857 0.70357143 0.68214286\n",
      "  0.69642857 0.625      0.65833333 0.73611111 0.73888889 0.70833333\n",
      "  0.64444444 0.74       0.74888889 0.75333333 0.75777778 0.76      ]\n",
      " [0.68       0.7        0.75       0.8        0.76       0.82\n",
      "  0.70666667 0.81333333 0.78666667 0.83333333 0.83809524 0.90952381\n",
      "  0.87619048 0.7952381  0.82857143 0.86071429 0.80714286 0.83571429\n",
      "  0.84285714 0.825      0.88055556 0.83611111 0.78611111 0.84166667\n",
      "  0.77777778 0.78444444 0.83111111 0.73111111 0.77555556 0.78      ]\n",
      " [0.76       0.78       0.74       0.71       0.8        0.80666667\n",
      "  0.81333333 0.82       0.82666667 0.83333333 0.83809524 0.81428571\n",
      "  0.79047619 0.82380952 0.8        0.80714286 0.72857143 0.67857143\n",
      "  0.69285714 0.7        0.70555556 0.73888889 0.76666667 0.77222222\n",
      "  0.75555556 0.76222222 0.76666667 0.75111111 0.67111111 0.66      ]] acc [[0.825      0.82278481 0.83333333 0.83116883 0.82894737 0.69333333\n",
      "  0.68918919 0.68493151 0.68055556 0.67605634 0.68571429 0.68115942\n",
      "  0.67647059 0.67164179 0.66666667 0.69230769 0.6875     0.73015873\n",
      "  0.70967742 0.7704918  0.76666667 0.72881356 0.67241379 0.77192982\n",
      "  0.76785714 0.76363636 0.75925926 0.75471698 0.76923077 0.76470588]\n",
      " [0.6375     0.63291139 0.78205128 0.77922078 0.77631579 0.77333333\n",
      "  0.62162162 0.61643836 0.61111111 0.6056338  0.6        0.71014493\n",
      "  0.70588235 0.70149254 0.6969697  0.69230769 0.6875     0.6984127\n",
      "  0.70967742 0.70491803 0.7        0.71186441 0.74137931 0.73684211\n",
      "  0.73214286 0.72727273 0.72222222 0.71698113 0.71153846 0.70588235]\n",
      " [0.8125     0.81012658 0.80769231 0.83116883 0.78947368 0.77333333\n",
      "  0.77027027 0.76712329 0.80555556 0.81690141 0.81428571 0.8115942\n",
      "  0.80882353 0.82089552 0.8030303  0.83076923 0.828125   0.82539683\n",
      "  0.82258065 0.81967213 0.81666667 0.83050847 0.82758621 0.8245614\n",
      "  0.83928571 0.83636364 0.83333333 0.83018868 0.82692308 0.82352941]\n",
      " [0.6375     0.63291139 0.62820513 0.63636364 0.64473684 0.64\n",
      "  0.64864865 0.65753425 0.72222222 0.71830986 0.71428571 0.71014493\n",
      "  0.73529412 0.73134328 0.72727273 0.66153846 0.65625    0.66666667\n",
      "  0.66129032 0.85245902 0.66666667 0.66101695 0.65517241 0.64912281\n",
      "  0.64285714 0.63636364 0.64814815 0.64150943 0.84615385 0.82352941]\n",
      " [0.8125     0.81012658 0.80769231 0.80519481 0.81578947 0.81333333\n",
      "  0.81081081 0.75342466 0.75       0.8028169  0.8        0.79710145\n",
      "  0.79411765 0.79104478 0.75757576 0.75384615 0.75       0.74603175\n",
      "  0.74193548 0.73770492 0.73333333 0.74576271 0.74137931 0.73684211\n",
      "  0.71428571 0.72727273 0.72222222 0.71698113 0.75       0.74509804]\n",
      " [0.7375     0.72151899 0.73076923 0.72727273 0.76315789 0.77333333\n",
      "  0.77027027 0.76712329 0.76388889 0.8028169  0.8        0.76811594\n",
      "  0.76470588 0.76119403 0.75757576 0.78461538 0.78125    0.77777778\n",
      "  0.79032258 0.78688525 0.78333333 0.77966102 0.79310345 0.78947368\n",
      "  0.78571429 0.78181818 0.77777778 0.77358491 0.76923077 0.76470588]\n",
      " [0.7375     0.73417722 0.73076923 0.79220779 0.78947368 0.78666667\n",
      "  0.72972973 0.7260274  0.76388889 0.78873239 0.78571429 0.7826087\n",
      "  0.77941176 0.79104478 0.78787879 0.78461538 0.78125    0.77777778\n",
      "  0.77419355 0.7704918  0.76666667 0.77966102 0.77586207 0.77192982\n",
      "  0.76785714 0.76363636 0.75925926 0.77358491 0.76923077 0.76470588]\n",
      " [0.8125     0.79746835 0.82051282 0.80519481 0.84210526 0.84\n",
      "  0.83783784 0.82191781 0.84722222 0.84507042 0.84285714 0.85507246\n",
      "  0.64705882 0.64179104 0.63636364 0.64615385 0.640625   0.63492063\n",
      "  0.80645161 0.80327869 0.8        0.81355932 0.84482759 0.84210526\n",
      "  0.83928571 0.81818182 0.81481481 0.81132075 0.80769231 0.82352941]\n",
      " [0.6625     0.65822785 0.66666667 0.7012987  0.71052632 0.69333333\n",
      "  0.67567568 0.79452055 0.79166667 0.78873239 0.78571429 0.7826087\n",
      "  0.77941176 0.7761194  0.77272727 0.76923077 0.828125   0.77777778\n",
      "  0.77419355 0.7704918  0.78333333 0.79661017 0.79310345 0.78947368\n",
      "  0.78571429 0.78181818 0.77777778 0.79245283 0.76923077 0.74509804]\n",
      " [0.625      0.62025316 0.61538462 0.67532468 0.61842105 0.61333333\n",
      "  0.60810811 0.60273973 0.59722222 0.5915493  0.58571429 0.5942029\n",
      "  0.60294118 0.59701493 0.59090909 0.69230769 0.609375   0.6031746\n",
      "  0.59677419 0.60655738 0.6        0.59322034 0.5862069  0.57894737\n",
      "  0.57142857 0.58181818 0.57407407 0.66037736 0.59615385 0.64705882]]\n"
     ]
    }
   ],
   "source": [
    "print(validate, 'acc',accurary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
